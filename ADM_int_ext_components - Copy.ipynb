{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Association Data Mining on 'ExteriorComponents' and 'InteriorComponents' to identify sets of items that are typically customized together. \n",
    "\n",
    "This information can help in the marketing of customization services, by introducing promotional packages/discounts to convince customers to customize more than one component at a time. \n",
    "\n",
    "ADM(component, support, confidence, lift) used for only one of 'ExteriorComponents' or 'InteriorComponents'\n",
    "\n",
    "For ADM on both exterior and interior, use the last cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read excel file \n",
    "df = pd.read_excel(r\"C:\\Users\\verlyn\\OneDrive\\Desktop\\SCH5\\4829\\PRODUCT_SURVEY RESULTS_2023.xlsx\")\n",
    "\n",
    "# rename columns \n",
    "df.columns = [\"No.\", \"Age\", \"Gender\", \"Category\", \"MarriageStatus\", \"FactorsPurchase\", \"FreeCustomization\", \"ExteriorComponents\", \"InteriorComponents\", \"WTSCustomization\", \"WantOwnPersonalization\", \"WTSPersonalization\", \"PersonalizationJob\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADM(component, support, confidence, lift): \n",
    "   # component = str(component)\n",
    "    \n",
    "    # fill NaN values with 'None' \n",
    "    df[component].fillna(\"None\", inplace=True)\n",
    "    df_component = df[component]\n",
    "   \n",
    "    # one hot encoding \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    encoded_df = pd.DataFrame(mlb.fit_transform(df_component.str.split(';')), columns=mlb.classes_, index=df.index)\n",
    "    encoded_df = encoded_df.astype(bool)\n",
    "    \n",
    "    # Find frequent itemsets using the apriori algorithm\n",
    "    frequent_itemsets = apriori(encoded_df, min_support=support, use_colnames=True)\n",
    "\n",
    "    # Generate association rules from the frequent itemsets\n",
    "    # To compare rules based on two different matrics, need to calculate two matrics for each rule\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence)\n",
    "    rules = rules[rules['lift'] >= lift]\n",
    "    \n",
    "    print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            antecedents       consequents  antecedent support  \\\n",
      "0                  (Centre compartment)       (Dashboard)                0.48   \n",
      "3    (Door handles, Centre compartment)       (Dashboard)                0.24   \n",
      "4  (Centre compartment, Steering wheel)       (Dashboard)                0.32   \n",
      "5    (Door handles, Centre compartment)  (Steering wheel)                0.24   \n",
      "6             (Dashboard, Door handles)  (Steering wheel)                0.30   \n",
      "7        (Door handles, Steering wheel)       (Dashboard)                0.28   \n",
      "\n",
      "   consequent support  support  confidence      lift  leverage  conviction  \n",
      "0                0.84     0.42    0.875000  1.041667    0.0168        1.28  \n",
      "3                0.84     0.22    0.916667  1.091270    0.0184        1.92  \n",
      "4                0.84     0.28    0.875000  1.041667    0.0112        1.28  \n",
      "5                0.60     0.20    0.833333  1.388889    0.0560        2.40  \n",
      "6                0.60     0.24    0.800000  1.333333    0.0600        2.00  \n",
      "7                0.84     0.24    0.857143  1.020408    0.0048        1.12  \n"
     ]
    }
   ],
   "source": [
    "ADM('InteriorComponents', 0.2, 0.8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      antecedents   consequents  antecedent support  consequent support  \\\n",
      "1  (Side mirrors)  (Headlights)                0.32                0.44   \n",
      "2        (Wheels)  (Headlights)                0.66                0.44   \n",
      "3    (Headlights)      (Wheels)                0.44                0.66   \n",
      "\n",
      "   support  confidence      lift  leverage  conviction  \n",
      "1     0.20    0.625000  1.420455    0.0592    1.493333  \n",
      "2     0.34    0.515152  1.170799    0.0496    1.155000  \n",
      "3     0.34    0.772727  1.170799    0.0496    1.496000  \n"
     ]
    }
   ],
   "source": [
    "ADM('ExteriorComponents', 0.2, 0.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  antecedents                consequents  antecedent support  \\\n",
      "37  (Dashboard, Door handles)             (Side mirrors)                0.30   \n",
      "40             (Side mirrors)  (Dashboard, Door handles)                0.32   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \n",
      "37                0.32      0.2    0.666667  2.083333     0.104    2.040000  \n",
      "40                0.30      0.2    0.625000  2.083333     0.104    1.866667  \n"
     ]
    }
   ],
   "source": [
    "# combining interior and exterior components\n",
    "support = 0.2\n",
    "confidence = 0.6\n",
    "lift = 2\n",
    "\n",
    "df['ExteriorComponents'].fillna(\"None\", inplace=True)\n",
    "df['InteriorComponents'].fillna(\"None\", inplace=True)\n",
    "ext_components = df['ExteriorComponents']\n",
    "int_components = df[\"InteriorComponents\"]\n",
    "\n",
    "df[\"InteriorComponents\"] = df[\"InteriorComponents\"].astype(str)\n",
    "df[\"ExteriorComponents\"] = df[\"ExteriorComponents\"].astype(str)\n",
    "\n",
    "df_component = df[\"InteriorComponents\"].str.cat(df[\"ExteriorComponents\"], sep=';')\n",
    "\n",
    "# one hot encoding \n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_df = pd.DataFrame(mlb.fit_transform(df_component.str.split(';')), columns=mlb.classes_, index=df.index)\n",
    "encoded_df = encoded_df.astype(bool)\n",
    "\n",
    "# Find frequent itemsets using the apriori algorithm\n",
    "frequent_itemsets = apriori(encoded_df, min_support=support, use_colnames=True)\n",
    "\n",
    "# Generate association rules from the frequent itemsets\n",
    "# To compare rules based on two different matrics, need to calculate two matrics for each rule\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence)\n",
    "rules = rules[rules['lift'] >= lift]\n",
    "\n",
    "print(rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33d606a988c8e4c322766b33c86dcfa5ac302c2ff6d388d92c47ce910a401361"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
